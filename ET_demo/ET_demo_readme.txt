OverviewThe file ET_demo.m uses a simulated data set to demonstrate the model-based eye-tracking procedure. The simulation is based on a recording from a 96-electrode Utah-array, and contains 101 units whose stimulus tuning is based on models estimated from the recorded neural population (including 7 single-units and 94 multi-units). Using the default parameter settings, the script requires about 16GB of RAM. You can use a subset of the data by changing the parameter “useFrac”, which determines the fraction of the total data to use.The algorithm is divided into the following stages:1. First assuming the animal maintains perfect fixation (constant eye position at the 'origin'), we make initial estimates of the stimulus-processing models for all units.2. Starting from these initial model estimates, we then iterate between estimating a set of 'fixation-corrections' and re-estimating the models, given the current estimates of fixation-corrections.3. Starting from the best estimate of the fixation-corrections, we iterate between estimating a set of drift corrections, and re-estimating the models.The stimulus-processing models are based on the “Nonlinear input model” (NIM). The code thus requires that the NIMtoolbox is included in the Matlab path. It can be downloaded from: http://www.clfs.umd.edu/biology/ntlab/NIM/. Note that the folder of ‘helper functions’ must be included in the Matlab path as well.Data fileThe simulated data are contained in the file called simDATA.mat. This file contains the following variables, where T is the number of time samples, N is the number of units, and d is the number of bar ‘pixels’:dt: scalar containing the time resolution in seconds (0.01)sim_eyepos: Tx1 vector containing the true eye position (in degrees relative to the fixation point) at each time.Robs_mat: TxN matrix containing the spike counts for each of unit, at each time bin.orig_mods: 1xN struct array containing the stimulus processing models for each unit (at a spatial resolution of 2x the stimulus resolution, or 0.028 degrees).stim_mat: Txd matrix containing the pixel values of the 'random-bar' stimulus in each frame. -1 = black, 0 = gray, 1 = white.saccade_start_inds/saccade_stop_inds: Vectors containing the index values when detected microsaccades start and stop.trial_start_inds/trial_stop_inds: Vectors containing the index values when trials start/stop (trial duration of ~3.7 sec).Model OutputThe key outputs of the model are fin_tot_corr and fin_tot_std. The former is the estimated eye position  (in degrees) as a function of time, and the latter is the estimated SD (in degrees) of the posterior distribution at each time. The code creates a plot comparing the estimated eye position with the true eye position for each simulated trial.